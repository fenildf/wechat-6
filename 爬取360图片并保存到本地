import os
import requests
from urllib.parse import urlencode
from hashlib import md5
from multiprocessing.pool import Pool

GROUP_START = 1
GROUP_END = 1



def get_page(offset):
    params = {
        'ch': 'photography',
        'listtype': 'new',
        'sn':offset * 30
    }
    url = 'https://image.so.com/zj?' + urlencode(params)
    url2 = 'http://image.so.com/zj?ch=photography&sn=30&listtype=new&temp=1'
    print(url)
    response = requests.get(url)
    print(response.status_code)

    try:
        response = requests.get(url)
        if response.status_code == 200:
            print('good')
            return response.json()

    except requests.ConnectionError:
        print('error')
        return None




def get_images(json):
    data = json.get('list')
    if data:
        for item in data:
            # print(item)
            # image_list = item.get('list')
            title = item.get('group_title')
            yield {
                'image': item.get('qhimg_url'),
                'title': title
            }
            #print(item)




def save_image(item):
    if not os.path.exists(item.get('title')):
        os.mkdir(item.get('title'))
    try:

        new_image_url = item.get('image')
        response = requests.get(new_image_url)
        if response.status_code == 200:
            file_path = '{0}/{1}.{2}'.format(item.get('title'), md5(response.content).hexdigest(), 'jpg')
            if not os.path.exists(file_path):
                with open(file_path, 'wb')as f:
                    f.write(response.content)
            else:
                print('Already Downloaded', file_path)
    except requests.ConnectionError:
        print('Failed to save image')


def main(offset):
    json = get_page(offset)
    for item in get_images(json):
        print(item)
        save_image(item)

main(1)
